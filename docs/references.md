* *Rafailov et al., “Direct Preference Optimization: Your Language Model is Secretly a Reward Model,” 2023*
* *Hugging Face TRL Documentation — DPOTrainer*
* *“Simplifying RLHF with DPO,” Hugging Face Blog, 2023*
